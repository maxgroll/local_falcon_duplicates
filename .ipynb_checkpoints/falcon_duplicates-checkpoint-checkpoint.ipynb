{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a53de75-4c3b-43cd-b7f6-242b76e2064f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e1d23a659e4bc8bbfa08e2c2ee0e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.csv', description='Upload', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3807ee33184f86b8184b223a7ddb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Process Uploaded File', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7af458cb3124b11bb5ea487e324855e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Cleanup Generated Files', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55926b1a66844cf8ac8e28493d177f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import FileLink, display, clear_output\n",
    "import io\n",
    "from ipywidgets import FileUpload, Button, Output\n",
    "import os\n",
    "import openpyxl\n",
    "\n",
    "# Function to read CSV with semicolon as delimiter\n",
    "def read_csv_with_semicolon(file_content):\n",
    "    return pd.read_csv(io.StringIO(file_content.decode('ISO-8859-1')), delimiter=';')\n",
    "\n",
    "def find_duplicate_place_ids_for_sheets(df, place_id_col):\n",
    "    \"\"\"\n",
    "    Marks duplicate place IDs in the DataFrame.\n",
    "    Adds a new column 'Is Duplicate' to indicate whether the row is a duplicate.\n",
    "    \"\"\"\n",
    "    # Mark duplicates as True except for the first occurrence\n",
    "    df['Is Duplicate'] = df.duplicated(place_id_col, keep=False)\n",
    "    # Sort by place_id_col to group duplicates together when viewing the Excel file\n",
    "    return df.sort_values(by=place_id_col)\n",
    "\n",
    "\n",
    "def process_file_and_save_summary(df, place_id_col, file_name):\n",
    "    \"\"\"\n",
    "    Processes the DataFrame to find and mark duplicates, saves the processed DataFrame,\n",
    "    and a summary of duplicates to an Excel file with two sheets: 'Detailed' and 'Summary'.\n",
    "    \"\"\"\n",
    "    # Mark duplicates in the DataFrame\n",
    "    df['Is Duplicate'] = df.duplicated(place_id_col, keep=False)\n",
    "    \n",
    "    # Find all unique duplicate IDs\n",
    "    duplicate_ids = df.loc[df['Is Duplicate'], place_id_col].unique()\n",
    "    \n",
    "    # Prepare summary DataFrame with each duplicate ID in a new row\n",
    "    summary_df = pd.DataFrame(duplicate_ids, columns=[place_id_col])\n",
    "    summary_df.index += 1  # Optional: Adjust index to start from 1 for better readability in Excel\n",
    "    \n",
    "    # Count total additional duplicates\n",
    "    total_additional_duplicates = len(df.loc[df['Is Duplicate']]) - len(duplicate_ids)\n",
    "    # Add a row at the beginning of the summary DataFrame for the total count\n",
    "    summary_df.loc[0] = [f\"Total Additional Duplicates: {total_additional_duplicates}\"]\n",
    "    summary_df.sort_index(inplace=True)  # Ensure the total count row is at the top\n",
    "    \n",
    "    # Save both the detailed DataFrame and the summary to the same Excel file\n",
    "    output_filename = f\"{file_name}_with_summary.xlsx\"\n",
    "    #with pd.ExcelWriter(output_filename) as writer:\n",
    "        #df.to_excel(writer, sheet_name='Detailed', index=False)\n",
    "        #summary_df.to_excel(writer, sheet_name='Summary', index_label='Index')\n",
    "\n",
    "    #####\n",
    "    with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
    "        df.to_excel(writer, sheet_name='Detailed', index=False)\n",
    "        # After saving, access the openpyxl workbook and sheet to enable filters\n",
    "        workbook = writer.book\n",
    "        detailed_sheet = writer.sheets['Detailed']\n",
    "\n",
    "        # Iterate over dataframe data to find the maximum length\n",
    "        for col in df:\n",
    "        # Finding the maximum length of data in each column\n",
    "            max_length = max(\n",
    "                (len(str(cell)) for cell in df[col]), # Iterate through all rows in column to find max length\n",
    "                default=50 # Default column width\n",
    "            )\n",
    "            # Adjust the column letter (Excel columns start from 1)\n",
    "            col_index = df.columns.get_loc(col) + 1\n",
    "            col_letter = openpyxl.utils.get_column_letter(col_index)\n",
    "            # Set the column width\n",
    "            detailed_sheet.column_dimensions[col_letter].width = max_length\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        detailed_sheet.auto_filter.ref = detailed_sheet.dimensions\n",
    "        \n",
    "        summary_df.to_excel(writer, sheet_name='Summary', index_label='Index')\n",
    "        summary_sheet = writer.sheets['Summary']\n",
    "        summary_sheet.auto_filter.ref = summary_sheet.dimensions\n",
    "        #####\n",
    "    \n",
    "    return output_filename\n",
    "\n",
    "# Initialize widgets\n",
    "upload = FileUpload(accept='.csv', multiple=True)\n",
    "process_button = Button(description=\"Process Uploaded File\")\n",
    "output_area = Output()\n",
    "\n",
    "# Assuming 'place_id_col' is set to the correct column name in your CSV\n",
    "place_id_col = 'Location_Place_ID'  # Adjust this to your specific column name for place IDs\n",
    "\n",
    "\n",
    "def process_uploaded_file(b=None):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        #print(upload.value)\n",
    "        if upload.value:\n",
    "            for file in upload.value:\n",
    "                file_info = file # Assuming this accesses the uploaded file's info correctly\n",
    "                content = file_info['content']\n",
    "                file_name = file_info['name'].split('.')[0]\n",
    "            \n",
    "                # Prepare the content for processing\n",
    "                content_io = io.StringIO(content.tobytes().decode('ISO-8859-1'))\n",
    "                df = pd.read_csv(content_io, delimiter=';')\n",
    "            \n",
    "                # Process the file and generate an output filename\n",
    "                output_filename = process_file_and_save_summary(df, 'Location_Place_ID', file_name)\n",
    "            \n",
    "                # Display the download link for the output file\n",
    "                display(FileLink(output_filename))\n",
    "        else:\n",
    "            print(\"No file uploaded.\")\n",
    "\n",
    "\n",
    "cleanup_button = Button(description=\"Cleanup Generated Files\")\n",
    "\n",
    "@output_area.capture(clear_output=True)\n",
    "def cleanup_files(b):\n",
    "    #Specify the pattern or directory of files to be cleaned up\n",
    "    directory = \".\"  # Current directory; adjust as needed\n",
    "  \n",
    "    pattern = \".xlsx\"  # Adjust based on how your files are named\n",
    "    if any(fname.endswith(pattern) for fname in os.listdir(directory)):\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(pattern):\n",
    "                os.remove(os.path.join(directory, filename))\n",
    "                print(f\"Deleted {filename}\")\n",
    "    else:\n",
    "         print('No files to delete')\n",
    "    \n",
    "cleanup_button.on_click(cleanup_files)\n",
    "\n",
    "# Attach the event handler to the process button\n",
    "process_button.on_click(process_uploaded_file)\n",
    "\n",
    "# Display UI elements\n",
    "display(upload, process_button,cleanup_button, output_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0334e40d-3320-41d8-8ace-6c054f92b296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
