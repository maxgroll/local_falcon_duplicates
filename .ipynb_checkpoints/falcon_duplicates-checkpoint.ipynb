{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e34d005-c364-4b11-a8aa-508423964d9e",
   "metadata": {},
   "source": [
    "# Local Falcon Location ID duplicate finder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9bbea2-d483-4802-adb3-cb4970ee35d7",
   "metadata": {},
   "source": [
    "> Use this script to find duplicate Location IDs in Local Falcon CSV Files and get a an .xlsx File where you can filter for those IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09331ca-f078-4daf-9811-d268e3d1b6d1",
   "metadata": {},
   "source": [
    "> run the script below and then scroll down to upload the files you need to find dudplicates in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a53de75-4c3b-43cd-b7f6-242b76e2064f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- upload your files:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be2ee56086cb42989db4ab82022ecb4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.csv', description='Upload', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- process the files:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549e291f85ce4546adecddd2cbe87cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Process Uploaded File', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **The downloadable files in .xlsx will appear below as links**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbf16a520b948dfa82e3d5399369e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- please delete the files from the Backend **once finished** with the downloads"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f94d995e0a4a9ca52f5245a985da01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Cleanup Generated Files', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import FileLink, display, clear_output, Markdown\n",
    "import io\n",
    "from ipywidgets import FileUpload, Button, Output\n",
    "import os\n",
    "import openpyxl\n",
    "\n",
    "# Function to display markdown text\n",
    "def print_markdown(text):\n",
    "    display(Markdown(text))\n",
    "\n",
    "# Function to read CSV with semicolon as delimiter\n",
    "def read_csv_with_semicolon(file_content):\n",
    "    return pd.read_csv(io.StringIO(file_content.decode('ISO-8859-1')), delimiter=';')\n",
    "\n",
    "def find_duplicate_place_ids_for_sheets(df, place_id_col):\n",
    "    \"\"\"\n",
    "    Marks duplicate place IDs in the DataFrame.\n",
    "    Adds a new column 'Is Duplicate' to indicate whether the row is a duplicate.\n",
    "    \"\"\"\n",
    "    # Mark duplicates as True except for the first occurrence\n",
    "    df['Is Duplicate'] = df.duplicated(place_id_col, keep=False)\n",
    "    # Sort by place_id_col to group duplicates together when viewing the Excel file\n",
    "    return df.sort_values(by=place_id_col)\n",
    "\n",
    "\n",
    "def process_file_and_save_summary(df, place_id_col, file_name):\n",
    "    \"\"\"\n",
    "    Processes the DataFrame to find and mark duplicates, saves the processed DataFrame,\n",
    "    and a summary of duplicates to an Excel file with two sheets: 'Detailed' and 'Summary'.\n",
    "    \"\"\"\n",
    "    # Mark duplicates in the DataFrame\n",
    "    df['Is Duplicate'] = df.duplicated(place_id_col, keep=False)\n",
    "    \n",
    "    # Find all unique duplicate IDs\n",
    "    duplicate_ids = df.loc[df['Is Duplicate'], place_id_col].unique()\n",
    "    \n",
    "    # Prepare summary DataFrame with each duplicate ID in a new row\n",
    "    summary_df = pd.DataFrame(duplicate_ids, columns=[place_id_col])\n",
    "    summary_df.index += 1  # Optional: Adjust index to start from 1 for better readability in Excel\n",
    "    \n",
    "    # Count total additional duplicates\n",
    "    total_additional_duplicates = len(df.loc[df['Is Duplicate']]) - len(duplicate_ids)\n",
    "    # Add a row at the beginning of the summary DataFrame for the total count\n",
    "    summary_df.loc[0] = [f\"Total Additional Duplicates: {total_additional_duplicates}\"]\n",
    "    summary_df.sort_index(inplace=True)  # Ensure the total count row is at the top\n",
    "    \n",
    "    # Save both the detailed DataFrame and the summary to the same Excel file\n",
    "    output_filename = f\"{file_name}_with_summary.xlsx\"\n",
    "   \n",
    "    with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
    "        df.to_excel(writer, sheet_name='Detailed', index=False)\n",
    "        # After saving, access the openpyxl workbook and sheet to enable filters\n",
    "        workbook = writer.book\n",
    "        detailed_sheet = writer.sheets['Detailed']\n",
    "\n",
    "        # Iterate over dataframe data to find the maximum length\n",
    "        for col in df:\n",
    "        # Finding the maximum length of data in each column\n",
    "            max_length = max(\n",
    "                (len(str(cell)) for cell in df[col]), # Iterate through all rows in column to find max length\n",
    "                default=10 # Default column width\n",
    "            )\n",
    "            # Adjust the column letter (Excel columns start from 1)\n",
    "            col_index = df.columns.get_loc(col) + 1\n",
    "            col_letter = openpyxl.utils.get_column_letter(col_index)\n",
    "            # Set the column width\n",
    "            detailed_sheet.column_dimensions[col_letter].width = max_length + 2\n",
    "        \n",
    "        detailed_sheet.auto_filter.ref = detailed_sheet.dimensions\n",
    "        \n",
    "        summary_df.to_excel(writer, sheet_name='Summary', index_label='Index')\n",
    "        summary_sheet = writer.sheets['Summary']\n",
    "        summary_sheet.auto_filter.ref = summary_sheet.dimensions\n",
    "    \n",
    "    return output_filename\n",
    "\n",
    "# Initialize widgets\n",
    "upload = FileUpload(accept='.csv', multiple=True)\n",
    "process_button = Button(description=\"Process Uploaded File\")\n",
    "output_area = Output()\n",
    "\n",
    "# Assuming 'place_id_col' is set to the correct column name in your CSV\n",
    "place_id_col = 'Location_Place_ID'  # Adjust this to your specific column name for place IDs\n",
    "\n",
    "\n",
    "def process_uploaded_files(b=None):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        #print(upload.value)\n",
    "        if upload.value:\n",
    "            for file in upload.value:\n",
    "                file_info = file # Assuming this accesses the uploaded file's info correctly\n",
    "                content = file_info['content']\n",
    "                file_name = file_info['name'].split('.')[0]\n",
    "            \n",
    "                # Prepare the content for processing\n",
    "                content_io = io.StringIO(content.tobytes().decode('ISO-8859-1'))\n",
    "                df = pd.read_csv(content_io, delimiter=';')\n",
    "            \n",
    "                # Process the file and generate an output filename\n",
    "                output_filename = process_file_and_save_summary(df, 'Location_Place_ID', file_name)\n",
    "            \n",
    "                # Display the download link for the output file\n",
    "                display(FileLink(output_filename))\n",
    "        else:\n",
    "            print(\"No file uploaded.\")\n",
    "\n",
    "\n",
    "cleanup_button = Button(description=\"Cleanup Generated Files\")\n",
    "\n",
    "@output_area.capture(clear_output=True)\n",
    "def cleanup_files(b):\n",
    "    #Specify the pattern or directory of files to be cleaned up\n",
    "    directory = \".\"  # Current directory; adjust as needed\n",
    "  \n",
    "    pattern = \".xlsx\"  # Adjust based on how your files are named\n",
    "    if any(fname.endswith(pattern) for fname in os.listdir(directory)):\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(pattern):\n",
    "                os.remove(os.path.join(directory, filename))\n",
    "                print(f\"Deleted {filename}\")\n",
    "        print_markdown(\"> **Thank you for keeping the Backend clean :)**\")\n",
    "    else:\n",
    "         print('No files to delete')\n",
    "\n",
    "\n",
    "cleanup_button.on_click(cleanup_files)\n",
    "\n",
    "# Attach the event handler to the process button\n",
    "process_button.on_click(process_uploaded_files)\n",
    "\n",
    "# Display UI elements\n",
    "#display(upload, print_markdown(\"-upload your files\"), process_button,cleanup_button, output_area)\n",
    "print_markdown(\"- upload your files:\")\n",
    "display(upload)\n",
    "print_markdown(\"- process the files:\")\n",
    "display(process_button)\n",
    "print_markdown('- **The downloadable files in .xlsx will appear below as links**')\n",
    "display(output_area)\n",
    "print_markdown('- please delete the files from the Backend **once finished** with the downloads')\n",
    "display(cleanup_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cfd887-1057-419e-9def-32acde5dcf0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
